{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Flow for Mobility Robustness Optimization (MRO)\n",
    "\n",
    "This notebook outlines the flow from loading the initial data to executing the `perform_attachment_hyst_ttt` function for MRO with hysteresis and time-to-trigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that 'UE_data_20UE_100ticks.csv' and 'topology.csv'\n",
    "# are present in the './Data/MRO/' directory.\n",
    "ue_data = pd.read_csv('./Data/MRO/UE_data_20UE_100ticks.csv')\n",
    "topology = pd.read_csv('./Data/MRO/topology.csv')\n",
    "ue_data = ue_data.rename(columns={'mock_ue_id': 'ue_id'})\n",
    "\n",
    "# Apply the same topology modifications as in the original notebook\n",
    "topology.loc[topology['cell_id'] == 'cell_2', 'cell_lat'] = 0\n",
    "topology.loc[topology['cell_id'] == 'cell_3', 'cell_lat'] = 90\n",
    "topology.loc[topology['cell_id'] == 'cell_1', 'cell_lat'] = -90\n",
    "topology.loc[topology['cell_id'] == 'cell_2', 'cell_lon'] = 0\n",
    "topology.loc[topology['cell_id'] == 'cell_3', 'cell_lon'] = 180\n",
    "topology.loc[topology['cell_id'] == 'cell_1', 'cell_lon'] = -180\n",
    "topology.loc[topology['cell_id'] == 'cell_2', 'cell_carrier_freq_mhz'] = 2100\n",
    "topology.loc[topology['cell_id'] == 'cell_3', 'cell_carrier_freq_mhz'] = 2100\n",
    "topology.loc[topology['cell_id'] == 'cell_1', 'cell_carrier_freq_mhz'] = 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af711178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS_EARTH_EQUATOR_KM = 6378.137\n",
    "CIRC_KM_TO_DEG_LAT: float = 180.0 / (math.pi * RADIUS_EARTH_EQUATOR_KM)\n",
    "LATENT_BACKGROUND_NOISE_DB = -150\n",
    "from typing import Any, List, Tuple, Union\n",
    "\n",
    "class GISTools:\n",
    "    R: float = 6378.1\n",
    "    OneDegree: float = R * 2 * math.pi / 360 * 1000\n",
    "\n",
    "    @staticmethod\n",
    "    def dist(l1: Tuple[float, float], l2: Tuple[float, float], abs_tol: float = 0.0002) -> float:\n",
    "        if GISTools.isclose(l1, l2, abs_tol=abs_tol):\n",
    "            return 0.0\n",
    "        [phi1, lam1] = [math.radians(l1[0]), math.radians(l1[1])]\n",
    "        [phi2, lam2] = [math.radians(l2[0]), math.radians(l2[1])]\n",
    "        d = (2 * GISTools.R * math.asin(math.sqrt(math.sin((phi2 - phi1) / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin((lam2 - lam1) / 2) ** 2)))\n",
    "        return d\n",
    "\n",
    "    @staticmethod\n",
    "    def isclose(A: Tuple[float, float], B: Tuple[float, float], abs_tol: float = 0.0002) -> bool:\n",
    "        try:\n",
    "            return math.isclose(A[0], B[0], abs_tol=abs_tol) and math.isclose(A[1], B[1], abs_tol=abs_tol)\n",
    "        except AttributeError:\n",
    "            return abs(A[0] - B[0]) <= max(1e-9 * max(abs(A[0]), abs(B[0])), abs_tol) and abs(A[1] - B[1]) <= max(1e-9 * max(abs(A[1]), abs(B[1])), abs_tol)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_log_distance(lat1, lon1, lat2, lon2, epsilon=1.0):\n",
    "        return np.log(epsilon + 1000.0 * GISTools.dist((lat1, lon1), (lat2, lon2)))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_relative_bearing(cell_az_deg, cell_lat, cell_lon, lat, lon):\n",
    "        def rel_bearing(heading_0_to_360: float, target_bearing_0_to_360: float) -> float:\n",
    "            return (target_bearing_0_to_360 - heading_0_to_360) % 360\n",
    "\n",
    "        def convert_bearing_0_to_360(bearing_minus180_to_180: float) -> float:\n",
    "            return (bearing_minus180_to_180 + 360) % 360\n",
    "\n",
    "        def get_bearing(l1: Tuple[float, float], l2: Tuple[float, float]) -> float:\n",
    "            [phi1, lam1] = [math.radians(l1[0]), math.radians(l1[1])]\n",
    "            [phi2, lam2] = [math.radians(l2[0]), math.radians(l2[1])]\n",
    "            y = math.sin(lam2 - lam1) * math.cos(phi2)\n",
    "            x = math.cos(phi1) * math.sin(phi2) - math.sin(phi1) * math.cos(phi2) * math.cos(lam2 - lam1)\n",
    "            return math.degrees(math.atan2(y, x))\n",
    "\n",
    "        return rel_bearing(\n",
    "            cell_az_deg,\n",
    "            convert_bearing_0_to_360(\n",
    "                get_bearing(\n",
    "                    (cell_lat, cell_lon),\n",
    "                    (lat, lon),\n",
    "                )\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def connect_ue_to_all_cells(ue_data, topology):\n",
    "    results = []\n",
    "    for _, ue_row in ue_data.iterrows():\n",
    "        ue_lat = ue_row['latitude']\n",
    "        ue_lon = ue_row['longitude']\n",
    "        for _, cell_row in topology.iterrows():\n",
    "            distance = GISTools.dist((ue_lat, ue_lon), (cell_row['cell_lat'], cell_row['cell_lon']))\n",
    "            combined_data = {\n",
    "                'ue_id': ue_row['ue_id'],\n",
    "                'longitude': ue_row['longitude'],\n",
    "                'latitude': ue_row['latitude'],\n",
    "                'tick': ue_row['tick'],\n",
    "                'cell_lat': cell_row['cell_lat'],\n",
    "                'cell_lon': cell_row['cell_lon'],\n",
    "                'cell_id': cell_row['cell_id'],\n",
    "                'cell_az_deg': cell_row['cell_az_deg'],\n",
    "                'cell_carrier_freq_mhz': cell_row['cell_carrier_freq_mhz'],\n",
    "                'distance': distance\n",
    "            }\n",
    "            results.append(combined_data)\n",
    "    full_data = pd.DataFrame(results)\n",
    "    full_data.drop(columns=['distance'], inplace=True)\n",
    "    return full_data\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    R = 6371.0\n",
    "    return R * c\n",
    "\n",
    "def calculate_received_power(tx_power_dbm, distance_km, frequency_mhz):\n",
    "    distance_m = distance_km * 1000\n",
    "    fspl_db = 20 * np.log10(distance_m) + 20 * np.log10(frequency_mhz) - 27.55\n",
    "    received_power_dbm = tx_power_dbm - fspl_db\n",
    "    return received_power_dbm\n",
    "\n",
    "def add_sinr_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def compute_layer_sinr(group: pd.DataFrame) -> float:\n",
    "        serving_row = group.loc[group['cell_rxpower_dbm'].idxmax()]\n",
    "        serving_rsrp_dbm = serving_row['cell_rxpower_dbm']\n",
    "        noise_linear = 10 ** (LATENT_BACKGROUND_NOISE_DB / 10)\n",
    "        total_power_linear = np.sum(10 ** (group['cell_rxpower_dbm'] / 10))\n",
    "        serving_power_linear = 10 ** (serving_rsrp_dbm / 10)\n",
    "        interference_linear = total_power_linear - serving_power_linear\n",
    "        total_interference_noise_dbm = 10 * np.log10(interference_linear + noise_linear)\n",
    "        sinr_db = serving_rsrp_dbm - total_interference_noise_dbm\n",
    "        return sinr_db\n",
    "\n",
    "    ue_sinr = {}\n",
    "    for ue_id, ue_group in df.groupby(\"ue_id\"):\n",
    "        sinr_by_freq = {}\n",
    "        for freq, freq_group in ue_group.groupby(\"cell_carrier_freq_mhz\"):\n",
    "            sinr_by_freq[freq] = compute_layer_sinr(freq_group)\n",
    "        max_sinr = max(sinr_by_freq.values())\n",
    "        ue_sinr[ue_id] = max_sinr\n",
    "    df = df.copy()\n",
    "    df[\"sinr_db\"] = df[\"ue_id\"].map(ue_sinr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_power_dbm = 23\n",
    "full_data = connect_ue_to_all_cells(ue_data, topology)\n",
    "full_data['distance_km'] = full_data.apply(lambda row: GISTools.get_log_distance(\n",
    "    row['latitude'], row['longitude'], row['cell_lat'], row['cell_lon']), axis=1)\n",
    "full_data['cell_rxpower_dbm'] = full_data.apply(lambda row: calculate_received_power(\n",
    "    tx_power_dbm, row['distance_km'], row['cell_carrier_freq_mhz']), axis=1)\n",
    "full_data = add_sinr_column(full_data)\n",
    "preproceseed_prediction_ue_data = full_data.rename(columns={'latitude': 'loc_y', 'longitude': 'loc_x'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyst = 1\n",
    "ttt = 5\n",
    "rlf_threshold = -24.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Attachment Logic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def _update_current_strongest(ue_data_for_current_tick, past_attachment, hyst):\n",
    "    merged_df = pd.merge(ue_data_for_current_tick, past_attachment,\n",
    "                             on='ue_id', how='left', suffixes=('', '_past'))\n",
    "    final_data = []\n",
    "    for ue_id, group in merged_df.groupby('ue_id'):\n",
    "        best_row = None\n",
    "        best_power = -999\n",
    "        for _, row in group.iterrows():\n",
    "            current_power = row['cell_rxpower_dbm']\n",
    "            past_cell_id = row['cell_id_past']\n",
    "            past_data = ue_data_for_current_tick[(ue_data_for_current_tick['ue_id'] == ue_id) &\n",
    "                                                (ue_data_for_current_tick['cell_id'] == past_cell_id)]\n",
    "            if not past_data.empty:\n",
    "                past_power = past_data.iloc[0]['cell_rxpower_dbm']\n",
    "            else:\n",
    "                past_power = -999\n",
    "            if current_power - past_power >= hyst:\n",
    "                if current_power > best_power:\n",
    "                    best_row = row\n",
    "                    best_power = current_power\n",
    "            else:\n",
    "                if past_power > best_power:\n",
    "                    best_row = past_data.iloc[0]\n",
    "                    best_power = past_power\n",
    "        if best_row is not None:\n",
    "            final_data.append(best_row)\n",
    "    final_df = pd.DataFrame(final_data)\n",
    "    final_df = final_df.loc[:, ~final_df.columns.str.endswith('_past')]\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def _update_current_attachment(strongest_server_history, ue_data_for_current_tick, past_attachment):\n",
    "    current_attachment_list = [] # contains updated ue -> cell + current data\n",
    "    merged_df = pd.concat(strongest_server_history, ignore_index=True)\n",
    "\n",
    "    #individual UE scope\n",
    "    for UE in ue_data_for_current_tick['ue_id'].unique():\n",
    "        # Check consistency for this specific UE\n",
    "        history_consistency_check = merged_df[merged_df['ue_id'] == UE]['cell_id'].nunique()\n",
    "        if history_consistency_check > 0:\n",
    "            consistent_cell_id = merged_df[merged_df['ue_id'] == UE]['cell_id'].unique()[0]\n",
    "\n",
    "            # attach consistent cell or past cell decision\n",
    "            if history_consistency_check == 1:\n",
    "                matching_rows = ue_data_for_current_tick[(ue_data_for_current_tick['ue_id'] == UE) & (ue_data_for_current_tick['cell_id'] == consistent_cell_id)]\n",
    "                if not matching_rows.empty:\n",
    "                    current_attachment_list.append(matching_rows.iloc[0].copy()) # Ensure a copy\n",
    "            else:\n",
    "                past_cell_id_df = past_attachment[past_attachment['ue_id'] == UE]['cell_id']\n",
    "                if not past_cell_id_df.empty:\n",
    "                    past_cell_id = past_cell_id_df.values[0]\n",
    "                    if past_cell_id == \"RLF\":\n",
    "                        highest_power_row = ue_data_for_current_tick[ue_data_for_current_tick['ue_id'] == UE].nlargest(1, 'cell_rxpower_dbm').iloc[0].copy() # Ensure a copy\n",
    "                        current_attachment_list.append(highest_power_row)\n",
    "                    else:\n",
    "                        matching_rows = ue_data_for_current_tick[(ue_data_for_current_tick['ue_id'] == UE) & (ue_data_for_current_tick['cell_id'] == past_cell_id)]\n",
    "                        if not matching_rows.empty:\n",
    "                            current_attachment_list.append(matching_rows.iloc[0].copy()) # Ensure a copy\n",
    "\n",
    "    current_attachment = pd.DataFrame(current_attachment_list).reset_index(drop=True)\n",
    "\n",
    "    # Ensure all UEs from current tick are present in current_attachment\n",
    "    current_attachment = pd.merge(ue_data_for_current_tick[['ue_id']].drop_duplicates(), current_attachment, on='ue_id', how='left')\n",
    "\n",
    "    return current_attachment\n",
    "\n",
    "def _check_hyst_in_current_tick(ue_data_for_current_tick: pd.DataFrame, current_attachment: pd.DataFrame, past_attachment: pd.DataFrame, hyst: float) -> pd.DataFrame:\n",
    "    if current_attachment.shape != past_attachment.shape:\n",
    "        raise AssertionError('current attachment and past attachment are not consistent. Check their shape, ue_id and cell_id columns.')\n",
    "    elif set(current_attachment['ue_id']) != set(past_attachment['ue_id']):\n",
    "        raise AssertionError('Error 2')\n",
    "\n",
    "    for i, curr in current_attachment.iterrows():\n",
    "        prev = past_attachment[past_attachment['ue_id'] == curr['ue_id']].iloc[0]\n",
    "        if curr['cell_id'] == prev['cell_id']:\n",
    "            continue\n",
    "        curr_attachment_rxpower = ue_data_for_current_tick[(ue_data_for_current_tick['ue_id'] == curr['ue_id']) & (ue_data_for_current_tick['cell_id'] == curr['cell_id'])]['cell_rxpower_dbm'].values[0]\n",
    "        try:\n",
    "            prev_attachment_rxpower = ue_data_for_current_tick[(ue_data_for_current_tick['ue_id'] == prev['ue_id']) & (ue_data_for_current_tick['cell_id'] == prev['cell_id'])]['cell_rxpower_dbm'].values[0]\n",
    "        except:\n",
    "            prev_attachment_rxpower = -np.inf\n",
    "        if curr_attachment_rxpower < prev_attachment_rxpower + hyst:\n",
    "            current_attachment.at[i, 'cell_id'] = prev['cell_id']\n",
    "            current_attachment.at[i, 'cell_rxpower_dbm'] = prev_attachment_rxpower\n",
    "\n",
    "    return current_attachment\n",
    "\n",
    "def check_rlf_threshold(df, current_tick_df, rlf_threshold):\n",
    "    updated_df = df.copy()\n",
    "    for ue_id in df['ue_id']:\n",
    "        df_ue = df[df['ue_id'] == ue_id]\n",
    "        current_tick_ue = current_tick_df[current_tick_df['ue_id'] == ue_id]\n",
    "        if not df_ue.empty and not current_tick_ue.empty:\n",
    "            max_sinr = df_ue['sinr_db'].values[0]\n",
    "            if max_sinr >= rlf_threshold:\n",
    "                continue\n",
    "            else:\n",
    "                max_sinr_current_tick = current_tick_ue['sinr_db'].max()\n",
    "                if max_sinr_current_tick >= rlf_threshold:\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'sinr_db'] = max_sinr_current_tick\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_id'] = current_tick_ue['cell_id'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_rxpower_dbm'] = current_tick_ue['cell_rxpower_dbm'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_lat'] = current_tick_ue['cell_lat'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_lon'] = current_tick_ue['cell_lon'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_carrier_freq_mhz'] = current_tick_ue['cell_carrier_freq_mhz'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_az_deg'] = current_tick_ue['cell_az_deg'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'distance_km'] = current_tick_ue['distance_km'].values[0]\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'relative_bearing'] = current_tick_ue['relative_bearing'].values[0]\n",
    "                else:\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'sinr_db'] = -np.inf\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_id'] = \"RLF\"\n",
    "                    updated_df.loc[updated_df['ue_id'] == ue_id, 'cell_rxpower_dbm'] = -np.inf\n",
    "    return updated_df\n",
    "\n",
    "# def perform_attachment_hyst_ttt_per_tick(ue_data_for_current_tick, strongest_server_history, past_attachment, ttt, hyst, use_strongest_server = False):\n",
    "#     current_strongest = ue_data_for_current_tick.loc[ue_data_for_current_tick.groupby('ue_id')['cell_rxpower_dbm'].idxmax()]\n",
    "#     if len(strongest_server_history) >= ttt:\n",
    "#         raise AssertionError(\"Error: Strongest_Server_History needs to be Less Than TTT!\")\n",
    "#     else:\n",
    "#         if use_strongest_server:\n",
    "#             current_attachment = current_strongest\n",
    "#             strongest_server_history.append(current_strongest)\n",
    "\n",
    "#         else:\n",
    "#             if ttt == len(strongest_server_history) + 1:\n",
    "#                 current_strongest = _update_current_strongest(ue_data_for_current_tick, past_attachment, hyst)\n",
    "#                 strongest_server_history.append(current_strongest)\n",
    "#                 current_attachment = _update_current_attachment(strongest_server_history, ue_data_for_current_tick, past_attachment)\n",
    "#                 current_attachment = _check_hyst_in_current_tick(ue_data_for_current_tick, current_attachment, past_attachment, hyst)\n",
    "#             else:\n",
    "#                 raise AssertionError(\"Length of Strongest Server History must be EQUALS to TTT - 1.\\n Call Perform Attachment with use_strongest_server = True\")\n",
    "\n",
    "#     if len(strongest_server_history) == ttt:\n",
    "#         strongest_server_history.pop(0)\n",
    "\n",
    "#     return strongest_server_history, current_attachment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed92f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a9e67f",
   "metadata": {},
   "source": [
    "## perform_attachment_hyst_ttt_per_tick Modified:\n",
    "To accommodate/fix Error while executing RL episode, did some refactoring without changing the base logic \n",
    "\n",
    "Error: Strongest_Server_History needs to be Less Than TTT!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96198bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_attachment_hyst_ttt_per_tick(ue_data_for_current_tick, strongest_server_history, past_attachment, ttt, hyst, use_strongest_server = False):\n",
    "    # --- START FIX ---\n",
    "    # Trim history if the new ttt requires a shorter history than currently stored.\n",
    "    # Ensure history length is at most ttt-1 before adding the current tick's info.\n",
    "    while len(strongest_server_history) >= ttt and ttt > 0: # Add ttt > 0 check for safety\n",
    "         strongest_server_history.pop(0) # Remove the oldest entry\n",
    "    # --- END FIX ---\n",
    "\n",
    "    current_strongest = ue_data_for_current_tick.loc[ue_data_for_current_tick.groupby('ue_id')['cell_rxpower_dbm'].idxmax()]\n",
    "\n",
    "    # --- the rest of the function's logic ---\n",
    "    if use_strongest_server:\n",
    "        current_attachment = current_strongest.copy()\n",
    "        strongest_server_history.append(current_strongest.copy())\n",
    "    else:\n",
    "        # This block is entered when len(history) == ttt - 1 (due to trimming + use_strongest_server_flag logic)\n",
    "        current_strongest = _update_current_strongest(ue_data_for_current_tick, past_attachment, hyst)\n",
    "        strongest_server_history.append(current_strongest.copy()) # Now len(history) == ttt\n",
    "        current_attachment = _update_current_attachment(strongest_server_history, ue_data_for_current_tick, past_attachment)\n",
    "\n",
    "    if len(strongest_server_history) == ttt:\n",
    "        strongest_server_history.pop(0)\n",
    "\n",
    "    return strongest_server_history, current_attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_attachment_hyst_ttt(ue_data, hyst, ttt, rlf_threshold):\n",
    "    strongest_server_hystory= []\n",
    "    current_attachment = pd.DataFrame()\n",
    "\n",
    "    tick_dataframes = {}\n",
    "    for tick in sorted(ue_data['tick'].unique()):\n",
    "        tick_dataframes[tick] = ue_data[ue_data['tick'] == tick].copy()\n",
    "\n",
    "    cell_attached_df = pd.DataFrame()\n",
    "    for tick in range(len(tick_dataframes)):\n",
    "        if ttt - 1 > len(strongest_server_hystory):\n",
    "            strongest_server_history, current_attachment = perform_attachment_hyst_ttt_per_tick(tick_dataframes[tick],strongest_server_hystory,current_attachment,ttt,hyst,use_strongest_server = True)\n",
    "        else:\n",
    "            strongest_server_history, current_attachment = perform_attachment_hyst_ttt_per_tick(tick_dataframes[tick],strongest_server_hystory,current_attachment,ttt,hyst,use_strongest_server = False)\n",
    "        current_attachment = check_rlf_threshold(current_attachment, tick_dataframes[tick], rlf_threshold)\n",
    "        cell_attached_df = pd.concat([cell_attached_df,current_attachment])\n",
    "\n",
    "    return cell_attached_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute `perform_attachment_hyst_ttt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "36ff1dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ue_id</th>\n",
       "      <th>loc_x</th>\n",
       "      <th>loc_y</th>\n",
       "      <th>tick</th>\n",
       "      <th>cell_lat</th>\n",
       "      <th>cell_lon</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_az_deg</th>\n",
       "      <th>cell_carrier_freq_mhz</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>cell_rxpower_dbm</th>\n",
       "      <th>sinr_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.625309</td>\n",
       "      <td>59.806764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.629500</td>\n",
       "      <td>-100.311970</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.625309</td>\n",
       "      <td>59.806764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cell_2</td>\n",
       "      <td>120</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.752768</td>\n",
       "      <td>-99.841523</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.625309</td>\n",
       "      <td>59.806764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>cell_3</td>\n",
       "      <td>240</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.027772</td>\n",
       "      <td>-99.432278</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>119.764151</td>\n",
       "      <td>54.857584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.595905</td>\n",
       "      <td>-100.294405</td>\n",
       "      <td>-23.848467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>119.764151</td>\n",
       "      <td>54.857584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cell_2</td>\n",
       "      <td>120</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.289273</td>\n",
       "      <td>-100.132420</td>\n",
       "      <td>-23.848467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ue_id       loc_x      loc_y  tick  cell_lat  cell_lon cell_id  \\\n",
       "0    0.0  -22.625309  59.806764   0.0     -90.0    -180.0  cell_1   \n",
       "1    0.0  -22.625309  59.806764   0.0       0.0       0.0  cell_2   \n",
       "2    0.0  -22.625309  59.806764   0.0      90.0     180.0  cell_3   \n",
       "3    1.0  119.764151  54.857584   0.0     -90.0    -180.0  cell_1   \n",
       "4    1.0  119.764151  54.857584   0.0       0.0       0.0  cell_2   \n",
       "\n",
       "   cell_az_deg  cell_carrier_freq_mhz  distance_km  cell_rxpower_dbm  \\\n",
       "0            0                   2100    16.629500       -100.311970   \n",
       "1          120                   2100    15.752768        -99.841523   \n",
       "2          240                   2100    15.027772        -99.432278   \n",
       "3            0                   2100    16.595905       -100.294405   \n",
       "4          120                   2100    16.289273       -100.132420   \n",
       "\n",
       "     sinr_db  \n",
       "0 -24.173384  \n",
       "1 -24.173384  \n",
       "2 -24.173384  \n",
       "3 -23.848467  \n",
       "4 -23.848467  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproceseed_prediction_ue_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ue_id</th>\n",
       "      <th>loc_x</th>\n",
       "      <th>loc_y</th>\n",
       "      <th>tick</th>\n",
       "      <th>cell_lat</th>\n",
       "      <th>cell_lon</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_az_deg</th>\n",
       "      <th>cell_carrier_freq_mhz</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>cell_rxpower_dbm</th>\n",
       "      <th>sinr_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.625309</td>\n",
       "      <td>59.806764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>cell_3</td>\n",
       "      <td>240</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.027772</td>\n",
       "      <td>-99.432278</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>119.764151</td>\n",
       "      <td>54.857584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>cell_3</td>\n",
       "      <td>240</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.179563</td>\n",
       "      <td>-99.519571</td>\n",
       "      <td>-23.848467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.095437</td>\n",
       "      <td>-20.253892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>RLF</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.865016</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-67.548009</td>\n",
       "      <td>-38.100941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.569455</td>\n",
       "      <td>-99.739854</td>\n",
       "      <td>-24.474944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>59.867089</td>\n",
       "      <td>-83.103930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>13.551107</td>\n",
       "      <td>-98.533881</td>\n",
       "      <td>-23.485879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ue_id       loc_x      loc_y  tick  cell_lat  cell_lon cell_id  \\\n",
       "2     0.0  -22.625309  59.806764   0.0      90.0     180.0  cell_3   \n",
       "5     1.0  119.764151  54.857584   0.0      90.0     180.0  cell_3   \n",
       "6     2.0   72.095437 -20.253892   0.0     -90.0    -180.0     RLF   \n",
       "9     3.0  -67.548009 -38.100941   0.0     -90.0    -180.0  cell_1   \n",
       "12    4.0   59.867089 -83.103930   0.0     -90.0    -180.0  cell_1   \n",
       "\n",
       "    cell_az_deg  cell_carrier_freq_mhz  distance_km  cell_rxpower_dbm  \\\n",
       "2           240                   2100    15.027772        -99.432278   \n",
       "5           240                   2100    15.179563        -99.519571   \n",
       "6             0                   2100    15.865016              -inf   \n",
       "9             0                   2100    15.569455        -99.739854   \n",
       "12            0                   2100    13.551107        -98.533881   \n",
       "\n",
       "      sinr_db  \n",
       "2  -24.173384  \n",
       "5  -23.848467  \n",
       "6        -inf  \n",
       "9  -24.474944  \n",
       "12 -23.485879  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = perform_attachment_hyst_ttt(preproceseed_prediction_ue_data, hyst=hyst, ttt=ttt, rlf_threshold=rlf_threshold)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73f6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULATE MRO OLD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dce9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rlf(df):\n",
    "    \"\"\"\n",
    "    Counts the number of times a mock_ue_id switches from any cell_id to 'RLF'.\n",
    "    \"\"\"\n",
    "    return (df['cell_id'] == \"RLF\").sum()\n",
    "\n",
    "def count_switches(df):\n",
    "    \"\"\"\n",
    "    Counts the number of times a ue_id switches cell_id to a different one (excluding 'RLF').\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    df = df.sort_values(by=['ue_id', 'tick'])  # Ensure correct order\n",
    "    prev_cells = {}\n",
    "    prev_ticks = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ue_id, cell_id, tick = row['ue_id'], row['cell_id'], row['tick']\n",
    "\n",
    "        if ue_id in prev_cells and prev_cells[ue_id] != cell_id and prev_cells[ue_id] is not None:\n",
    "            if tick == prev_ticks[ue_id] + 1 and cell_id != \"RLF\":\n",
    "                count += 1\n",
    "\n",
    "        prev_cells[ue_id] = cell_id\n",
    "        prev_ticks[ue_id] = tick\n",
    "\n",
    "    return count\n",
    "\n",
    "def calculate_mro_metric(ns_handover_count, nf_handover_count, prediction_ue_data):\n",
    "    # Constants for interruption times\n",
    "    ts = 50 / 1000  # Convert ms to seconds\n",
    "    t_nas = 1000 / 1000  # Convert ms to seconds\n",
    "\n",
    "    # Calculate total time (T) based on ticks; assuming each tick represents a uniform time slice\n",
    "    # This could be adjusted if ticks represent variable time slices\n",
    "    # Rather than passing the UE Data as whole we can send just an integar for tick\n",
    "    ticks = len(prediction_ue_data['tick'].unique())\n",
    "    tick_duration_seconds = 10000  # 10,000 second per tick\n",
    "    T = ticks * tick_duration_seconds\n",
    "\n",
    "    # Calculate D\n",
    "    D = T - (ns_handover_count * ts + nf_handover_count * t_nas)\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "08ae014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999799.45\n"
     ]
    }
   ],
   "source": [
    "print(calculate_mro_metric(count_switches(final_df), count_rlf(final_df), final_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997318ae",
   "metadata": {},
   "source": [
    "## RL for Optimising hyst and ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59941c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces # Use gymnasium spaces\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# Import other necessary libraries like stable_baselines3, BaseCallback etc.\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea856f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the training and testing data based on ticks\n",
    "unique_ticks = sorted(preproceseed_prediction_ue_data['tick'].unique())\n",
    "train_ticks = unique_ticks[:80]\n",
    "test_ticks = unique_ticks[80:]\n",
    "\n",
    "train_data = preproceseed_prediction_ue_data[preproceseed_prediction_ue_data['tick'].isin(train_ticks)].copy()\n",
    "test_data = preproceseed_prediction_ue_data[preproceseed_prediction_ue_data['tick'].isin(test_ticks)].copy()\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aaddf3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ue_id</th>\n",
       "      <th>loc_x</th>\n",
       "      <th>loc_y</th>\n",
       "      <th>tick</th>\n",
       "      <th>cell_lat</th>\n",
       "      <th>cell_lon</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_az_deg</th>\n",
       "      <th>cell_carrier_freq_mhz</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>cell_rxpower_dbm</th>\n",
       "      <th>sinr_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.432484</td>\n",
       "      <td>54.840405</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.595786</td>\n",
       "      <td>-100.294343</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.432484</td>\n",
       "      <td>54.840405</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cell_2</td>\n",
       "      <td>120</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.650544</td>\n",
       "      <td>-99.784975</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.432484</td>\n",
       "      <td>54.840405</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>cell_3</td>\n",
       "      <td>240</td>\n",
       "      <td>2100</td>\n",
       "      <td>15.180052</td>\n",
       "      <td>-99.519851</td>\n",
       "      <td>-24.173384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>1.0</td>\n",
       "      <td>123.680712</td>\n",
       "      <td>74.603708</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.723695</td>\n",
       "      <td>-100.361031</td>\n",
       "      <td>-23.848467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>1.0</td>\n",
       "      <td>123.680712</td>\n",
       "      <td>74.603708</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cell_2</td>\n",
       "      <td>120</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.209872</td>\n",
       "      <td>-100.089977</td>\n",
       "      <td>-23.848467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ue_id       loc_x      loc_y  tick  cell_lat  cell_lon cell_id  \\\n",
       "4800    0.0  -15.432484  54.840405  80.0     -90.0    -180.0  cell_1   \n",
       "4801    0.0  -15.432484  54.840405  80.0       0.0       0.0  cell_2   \n",
       "4802    0.0  -15.432484  54.840405  80.0      90.0     180.0  cell_3   \n",
       "4803    1.0  123.680712  74.603708  80.0     -90.0    -180.0  cell_1   \n",
       "4804    1.0  123.680712  74.603708  80.0       0.0       0.0  cell_2   \n",
       "\n",
       "      cell_az_deg  cell_carrier_freq_mhz  distance_km  cell_rxpower_dbm  \\\n",
       "4800            0                   2100    16.595786       -100.294343   \n",
       "4801          120                   2100    15.650544        -99.784975   \n",
       "4802          240                   2100    15.180052        -99.519851   \n",
       "4803            0                   2100    16.723695       -100.361031   \n",
       "4804          120                   2100    16.209872       -100.089977   \n",
       "\n",
       "        sinr_db  \n",
       "4800 -24.173384  \n",
       "4801 -24.173384  \n",
       "4802 -24.173384  \n",
       "4803 -23.848467  \n",
       "4804 -23.848467  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b7e4b",
   "metadata": {},
   "source": [
    "## New MRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "42b8cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_switches_and_pingpongs(df, pp_window=5): # pp_window in ticks\n",
    "    \"\"\"\n",
    "    Counts total successful handovers and ping-pong handovers.\n",
    "    A ping-pong is defined as A->B->A within pp_window ticks.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=['ue_id', 'tick'])\n",
    "    ho_count = 0\n",
    "    pp_count = 0\n",
    "    # Store recent history: ue_id -> list of (tick, cell_id) tuples\n",
    "    history = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ue_id, cell_id, tick = row['ue_id'], row['cell_id'], row['tick']\n",
    "\n",
    "        if ue_id not in history:\n",
    "            history[ue_id] = [(tick, cell_id)]\n",
    "            continue\n",
    "\n",
    "        last_tick, last_cell = history[ue_id][-1]\n",
    "\n",
    "        # Check for handover (excluding RLF)\n",
    "        if cell_id != last_cell and cell_id != \"RLF\" and last_cell != \"RLF\":\n",
    "             # Ensure handover is between consecutive ticks for counting (optional, depends on data density)\n",
    "             # if tick == last_tick + 1: # Uncomment if only consecutive tick HOs count\n",
    "             ho_count += 1\n",
    "             # Check for Ping-Pong (A->B->A pattern)\n",
    "             # Need at least 2 previous entries for A->B->A\n",
    "             if len(history[ue_id]) >= 2:\n",
    "                 prev_tick, prev_cell = history[ue_id][-2]\n",
    "                 # Is the current cell the same as the one before the last one?\n",
    "                 # Is it within the time window?\n",
    "                 if cell_id == prev_cell and (tick - prev_tick) <= pp_window:\n",
    "                     pp_count += 1\n",
    "\n",
    "        # Update history for this UE\n",
    "        history[ue_id].append((tick, cell_id))\n",
    "        # Optional: Trim history to keep it manageable (e.g., keep last pp_window + 5 entries)\n",
    "        # history[ue_id] = history[ue_id][-(pp_window + 5):]\n",
    "\n",
    "    return ho_count, pp_count\n",
    "\n",
    "def calculate_mro_metric_v2(handovers, pingpongs, rlfs, total_ticks, base_ho_penalty_s=0.1, pp_extra_penalty_s=0.5, rlf_penalty_s=1.0):\n",
    "    \"\"\"\n",
    "    Calculates an MRO score penalizing HOs, Ping-Pongs (extra), and RLFs.\n",
    "    Uses penalties directly instead of calculating total time T.\n",
    "    Goal is typically to MAXIMIZE this score (starts high, decreases with penalties).\n",
    "    Or flip signs to MINIMIZE penalties. Let's aim to maximize.\n",
    "\n",
    "    Args:\n",
    "        handovers (int): Total successful handovers.\n",
    "        pingpongs (int): Number of ping-pong handovers (subset of handovers).\n",
    "        rlfs (int): Number of Radio Link Failures.\n",
    "        total_ticks (int): Total duration in ticks (proxy for opportunity).\n",
    "        base_ho_penalty_s (float): Penalty for each normal handover (seconds equivalent).\n",
    "        pp_extra_penalty_s (float): *Additional* penalty for ping-pong (seconds equivalent).\n",
    "        rlf_penalty_s (float): Penalty for each RLF (seconds equivalent).\n",
    "\n",
    "    Returns:\n",
    "        float: MRO score. Higher is better.\n",
    "    \"\"\"\n",
    "    # Start with a base score proportional to duration\n",
    "    # We need a consistent baseline if not using T from original formula\n",
    "    # Let's use total_ticks as a simple baseline score (or 0 if minimizing penalties)\n",
    "    base_score = 0 # Let's minimize total penalty instead\n",
    "\n",
    "    normal_handovers = handovers - pingpongs\n",
    "    total_penalty = (normal_handovers * base_ho_penalty_s) + \\\n",
    "                    (pingpongs * (base_ho_penalty_s + pp_extra_penalty_s)) + \\\n",
    "                    (rlfs * rlf_penalty_s)\n",
    "\n",
    "    # Return negative penalty (higher score is better)\n",
    "    return -total_penalty\n",
    "\n",
    "    # --- OR --- Alternative: Maximize uptime-like metric (closer to original)\n",
    "    # tick_duration_s = 1.0 # Define a more realistic tick duration if needed\n",
    "    # effective_T = total_ticks * tick_duration_s\n",
    "    # score = effective_T - total_penalty\n",
    "    # return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c633f71",
   "metadata": {},
   "source": [
    "## Using old MRO metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "423df40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Replace 'import gym' with:\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces # Use gymnasium spaces\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# Import other necessary libraries like stable_baselines3, BaseCallback etc.\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (Keep your helper functions like GISTools, connect_ue_to_all_cells, etc.)\n",
    "# ...\n",
    "# (Keep your MRO metric functions like calculate_mro_metric, count_switches, count_rlf)\n",
    "# ...\n",
    "\n",
    "# %%\n",
    "# Define the RL Environment using Gymnasium\n",
    "class MRO_Env(gym.Env): # Inherit from gymnasium.Env\n",
    "    metadata = {\"render_modes\": [], \"render_fps\": 4} # Optional but good practice\n",
    "\n",
    "    def __init__(self, data, topology, reward_function, train_mode=True):\n",
    "        super().__init__() # Use super().__init__()\n",
    "        self.data = data\n",
    "        self.topology = topology\n",
    "        self.reward_function = reward_function\n",
    "        self.train_mode = train_mode\n",
    "        self.ticks = sorted(data['tick'].unique())\n",
    "        self.current_tick_index = 0\n",
    "        self.max_ticks = len(self.ticks)\n",
    "        self.hyst_range = [0.0, 5.0]\n",
    "        self.ttt_range = [1, 10]\n",
    "        # Note: self.ttt is set dynamically in step\n",
    "\n",
    "        # Define action space using gymnasium.spaces\n",
    "        self.action_space = spaces.Box(low=np.array([self.hyst_range[0], self.ttt_range[0]]),\n",
    "                                         high=np.array([self.hyst_range[1], self.ttt_range[1]]),\n",
    "                                         dtype=np.float32)\n",
    "\n",
    "        # Define observation space using gymnasium.spaces\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        self.strongest_server_history = []\n",
    "        # Initialize past_attachment with correct columns\n",
    "        self.required_cols_for_history = ['ue_id', 'cell_id', 'tick', 'cell_rxpower_dbm']\n",
    "        self.past_attachment = pd.DataFrame(columns=self.required_cols_for_history)\n",
    "        self.past_attachment_history = []\n",
    "\n",
    "    # Update reset signature for Gymnasium\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed) # Call super().reset(seed=seed)\n",
    "\n",
    "        self.current_tick_index = 0\n",
    "        self.strongest_server_history = []\n",
    "        self.past_attachment = pd.DataFrame(columns=self.required_cols_for_history) # Re-initialize\n",
    "        self.past_attachment_history = []\n",
    "\n",
    "        observation = np.array([self.current_tick_index / self.max_ticks], dtype=np.float32)\n",
    "        info = {} # Standard info dict for reset\n",
    "\n",
    "        # Gymnasium reset returns obs, info\n",
    "        return observation, info\n",
    "\n",
    "    # Ensure step returns 5 values\n",
    "    def step(self, action):\n",
    "        hyst, ttt_action = action[0], action[1]\n",
    "        hyst = np.clip(hyst, self.hyst_range[0], self.hyst_range[1])\n",
    "        # Ensure ttt is at least 1 after rounding\n",
    "        ttt = max(1, int(round(np.clip(ttt_action, self.ttt_range[0], self.ttt_range[1]))))\n",
    "        # self.ttt = ttt # No need to store self.ttt if only used locally in step\n",
    "\n",
    "        # Boundary check for safety\n",
    "        if self.current_tick_index >= self.max_ticks:\n",
    "             print(f\"Warning: Step called at or beyond max_ticks ({self.current_tick_index}/{self.max_ticks}). Returning dummy values.\")\n",
    "             # Return dummy values consistent with observation/action spaces and 5-tuple format\n",
    "             last_observation = np.array([1.0], dtype=np.float32) # Represent end state\n",
    "             return last_observation, 0, True, False, {\"status\": \"already finished\"}\n",
    "\n",
    "\n",
    "        current_tick = self.ticks[self.current_tick_index]\n",
    "        current_tick_data = self.data[self.data['tick'] == current_tick].copy()\n",
    "\n",
    "        # print(f\"****** Start Tick: {current_tick}, Hyst: {hyst:.2f}, TTT: {ttt}\") # Optional print\n",
    "\n",
    "        use_strongest_server_flag = len(self.strongest_server_history) < ttt - 1\n",
    "\n",
    "        # Call the simulation function (ensure it's defined correctly above)\n",
    "        self.strongest_server_history, current_attachment = perform_attachment_hyst_ttt_per_tick(\n",
    "            current_tick_data, self.strongest_server_history, self.past_attachment.copy(), ttt, hyst, use_strongest_server=use_strongest_server_flag\n",
    "        )\n",
    "\n",
    "        # Update self.past_attachment safely, ensuring required columns are present\n",
    "        if not current_attachment.empty:\n",
    "            # Ensure tick column exists (it should, but double-check)\n",
    "            if 'tick' not in current_attachment.columns:\n",
    "                 current_attachment['tick'] = current_tick\n",
    "\n",
    "            if all(col in current_attachment.columns for col in self.required_cols_for_history):\n",
    "                self.past_attachment = current_attachment[self.required_cols_for_history].copy()\n",
    "            # else: Keep the previous self.past_attachment if columns are missing\n",
    "        # else: Keep the previous self.past_attachment if current is empty\n",
    "\n",
    "        # --- Calculate reward only at the end ---\n",
    "        reward = 0\n",
    "        terminated = False # Replaces 'done' for natural termination\n",
    "        truncated = False # Replaces 'done' for time limit / artificial termination\n",
    "\n",
    "        self.current_tick_index += 1\n",
    "\n",
    "        # Check if episode is finished\n",
    "        if self.current_tick_index == self.max_ticks:\n",
    "            # Set appropriate done flag: terminated=False, truncated=True is common for time limits\n",
    "            terminated = False\n",
    "            truncated = True # Episode ended because max_ticks reached\n",
    "\n",
    "            if not self.past_attachment_history:\n",
    "                 print(\"Warning: past_attachment_history is empty at the end of the episode.\")\n",
    "                 handovers = 0\n",
    "                 rlf_count = 0\n",
    "                 reward = 0 # Or some baseline/penalty\n",
    "            else:\n",
    "                 final_df_episode = pd.concat(self.past_attachment_history).reset_index(drop=True)\n",
    "                 if not final_df_episode.empty:\n",
    "                      handovers = count_switches(final_df_episode)\n",
    "                      rlf_count = count_rlf(final_df_episode)\n",
    "                      reward = self.reward_function(handovers, rlf_count, self.data)\n",
    "                 else: # Should not happen if history was not empty, but safe check\n",
    "                      handovers = 0\n",
    "                      rlf_count = 0\n",
    "                      reward = 0\n",
    "\n",
    "            # Reset history only when episode truly ends (handled by SB3/Monitor usually)\n",
    "            # self.past_attachment_history = [] # Let Monitor handle reset logic\n",
    "        else:\n",
    "            # Append the current state *before* potentially finishing\n",
    "            if not self.past_attachment.empty: # Append only if valid attachment exists\n",
    "                self.past_attachment_history.append(self.past_attachment.copy())\n",
    "\n",
    "        # Prepare observation for the *next* state\n",
    "        # Use current_tick_index because it reflects the state *after* the step\n",
    "        observation = np.array([self.current_tick_index / self.max_ticks], dtype=np.float32)\n",
    "        info = {} # Store additional info if needed\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def close(self):\n",
    "        # Implement any necessary cleanup\n",
    "        pass\n",
    "\n",
    "# %%\n",
    "# (RewardCallback definition should be here if not already defined)\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class RewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A simple callback that can be used to print information during training.\n",
    "    Modify it to log or print specific details as needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RewardCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if episode is finished (using dones flag from locals, which combines terminated/truncated)\n",
    "        if self.locals[\"dones\"][0]:\n",
    "            info = self.locals[\"infos\"][0]\n",
    "            if 'episode' in info: # Check if Monitor wrapper added episode info\n",
    "                print(f\"Episode finished. Length={info['episode']['l']}, Reward={info['episode']['r']:.2f}\")\n",
    "                self.episode_rewards.append(info['episode']['r'])\n",
    "                self.episode_lengths.append(info['episode']['l'])\n",
    "        return True # Continue training\n",
    "\n",
    "# %%\n",
    "# Instantiate and train (ensure train_data, topology are defined)\n",
    "\n",
    "# Assuming train_data and topology are loaded and preprocessed correctly\n",
    "train_env = MRO_Env(train_data, topology, calculate_mro_metric, train_mode=True)\n",
    "print(\"** train_env created (using gymnasium)\")\n",
    "\n",
    "# PPO should automatically wrap the env with Monitor and DummyVecEnv if it's not a VecEnv\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "print(\"** model created\")\n",
    "\n",
    "reward_callback = RewardCallback()\n",
    "print(\"** reward callback created\")\n",
    "\n",
    "total_timesteps = 10000 # Adjust as needed\n",
    "model.learn(total_timesteps=total_timesteps, callback=reward_callback)\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af785294",
   "metadata": {},
   "source": [
    "## Using New MRO Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RL Environment using Gymnasium\n",
    "class MRO_Env(gym.Env): # Inherit from gymnasium.Env\n",
    "    metadata = {\"render_modes\": [], \"render_fps\": 4} # Optional but good practice\n",
    "\n",
    "    def __init__(self, data, topology, reward_function, train_mode=True):\n",
    "        super().__init__() # Use super().__init__()\n",
    "        self.data = data\n",
    "        self.topology = topology\n",
    "        self.reward_function = reward_function\n",
    "        self.train_mode = train_mode\n",
    "        self.ticks = sorted(data['tick'].unique())\n",
    "        self.current_tick_index = 0\n",
    "        self.max_ticks = len(self.ticks)\n",
    "        self.hyst_range = [0.0, 5.0]\n",
    "        self.ttt_range = [1, 10]\n",
    "        # Note: self.ttt is set dynamically in step\n",
    "\n",
    "        # Define action space using gymnasium.spaces\n",
    "        self.action_space = spaces.Box(low=np.array([self.hyst_range[0], self.ttt_range[0]]),\n",
    "                                         high=np.array([self.hyst_range[1], self.ttt_range[1]]),\n",
    "                                         dtype=np.float32)\n",
    "\n",
    "        # Define observation space using gymnasium.spaces\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        self.strongest_server_history = []\n",
    "        # Initialize past_attachment with correct columns\n",
    "        self.required_cols_for_history = ['ue_id', 'cell_id', 'tick', 'cell_rxpower_dbm']\n",
    "        self.past_attachment = pd.DataFrame(columns=self.required_cols_for_history)\n",
    "        self.past_attachment_history = []\n",
    "\n",
    "    # Update reset signature for Gymnasium\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed) # Call super().reset(seed=seed)\n",
    "\n",
    "        self.current_tick_index = 0\n",
    "        self.strongest_server_history = []\n",
    "        self.past_attachment = pd.DataFrame(columns=self.required_cols_for_history) # Re-initialize\n",
    "        self.past_attachment_history = []\n",
    "\n",
    "        observation = np.array([self.current_tick_index / self.max_ticks], dtype=np.float32)\n",
    "        info = {} # Standard info dict for reset\n",
    "\n",
    "        # Gymnasium reset returns obs, info\n",
    "        return observation, info\n",
    "\n",
    "    # Ensure step returns 5 values\n",
    "    def step(self, action):\n",
    "        hyst, ttt_action = action[0], action[1]\n",
    "        hyst = np.clip(hyst, self.hyst_range[0], self.hyst_range[1])\n",
    "        # Ensure ttt is at least 1 after rounding\n",
    "        ttt = max(1, int(round(np.clip(ttt_action, self.ttt_range[0], self.ttt_range[1]))))\n",
    "        # self.ttt = ttt # No need to store self.ttt if only used locally in step\n",
    "\n",
    "        # Boundary check for safety\n",
    "        if self.current_tick_index >= self.max_ticks:\n",
    "             print(f\"Warning: Step called at or beyond max_ticks ({self.current_tick_index}/{self.max_ticks}). Returning dummy values.\")\n",
    "             # Return dummy values consistent with observation/action spaces and 5-tuple format\n",
    "             last_observation = np.array([1.0], dtype=np.float32) # Represent end state\n",
    "             return last_observation, 0, True, False, {\"status\": \"already finished\"}\n",
    "\n",
    "\n",
    "        current_tick = self.ticks[self.current_tick_index]\n",
    "        current_tick_data = self.data[self.data['tick'] == current_tick].copy()\n",
    "\n",
    "        # print(f\"****** Start Tick: {current_tick}, Hyst: {hyst:.2f}, TTT: {ttt}\") # Optional print\n",
    "\n",
    "        use_strongest_server_flag = len(self.strongest_server_history) < ttt - 1\n",
    "\n",
    "        # Call the simulation function (ensure it's defined correctly above)\n",
    "        self.strongest_server_history, current_attachment = perform_attachment_hyst_ttt_per_tick(\n",
    "            current_tick_data, self.strongest_server_history, self.past_attachment.copy(), ttt, hyst, use_strongest_server=use_strongest_server_flag\n",
    "        )\n",
    "\n",
    "        # Update self.past_attachment safely, ensuring required columns are present\n",
    "        if not current_attachment.empty:\n",
    "            # Ensure tick column exists (it should, but double-check)\n",
    "            if 'tick' not in current_attachment.columns:\n",
    "                 current_attachment['tick'] = current_tick\n",
    "\n",
    "            if all(col in current_attachment.columns for col in self.required_cols_for_history):\n",
    "                self.past_attachment = current_attachment[self.required_cols_for_history].copy()\n",
    "            # else: Keep the previous self.past_attachment if columns are missing\n",
    "        # else: Keep the previous self.past_attachment if current is empty\n",
    "\n",
    "        # --- Calculate reward only at the end ---\n",
    "        reward = 0\n",
    "        terminated = False # Replaces 'done' for natural termination\n",
    "        truncated = False # Replaces 'done' for time limit / artificial termination\n",
    "\n",
    "        self.current_tick_index += 1\n",
    "\n",
    "        # Check if episode is finished\n",
    "        if self.current_tick_index == self.max_ticks:\n",
    "            # Set appropriate done flag: terminated=False, truncated=True is common for time limits\n",
    "            terminated = False\n",
    "            truncated = True # Episode ended because max_ticks reached\n",
    "\n",
    "            if not self.past_attachment_history:\n",
    "                 print(\"Warning: past_attachment_history is empty at the end of the episode.\")\n",
    "                 handovers = 0\n",
    "                 rlf_count = 0\n",
    "                 reward = 0 # Or some baseline/penalty\n",
    "            else:\n",
    "                 final_df_episode = pd.concat(self.past_attachment_history).reset_index(drop=True)\n",
    "                 if not final_df_episode.empty:\n",
    "                    # Use the new counting function\n",
    "                    ho_count, pp_count = count_switches_and_pingpongs(final_df_episode, pp_window=5) # Adjust window as needed\n",
    "                    rlf_count = count_rlf(final_df_episode)\n",
    "                    total_ticks_in_episode = len(self.ticks) # Or self.max_ticks\n",
    "\n",
    "                    # Use the new reward function\n",
    "                    # *** Tune these penalty values! ***\n",
    "                    reward = calculate_mro_metric_v2(ho_count, pp_count, rlf_count, total_ticks_in_episode,\n",
    "                                                    base_ho_penalty_s=0.4,  # e.g., 100ms penalty per HO\n",
    "                                                    pp_extra_penalty_s=1.4, # e.g., Additional 400ms for PP (total 500ms)\n",
    "                                                    rlf_penalty_s=1.0)      # e.g., 1s penalty per RLF\n",
    "                 else: # Should not happen if history was not empty, but safe check\n",
    "                      handovers = 0\n",
    "                      rlf_count = 0\n",
    "                      reward = 0\n",
    "\n",
    "            # Reset history only when episode truly ends (handled by SB3/Monitor usually)\n",
    "            # self.past_attachment_history = [] # Let Monitor handle reset logic\n",
    "        else:\n",
    "            # Append the current state *before* potentially finishing\n",
    "            if not self.past_attachment.empty: # Append only if valid attachment exists\n",
    "                self.past_attachment_history.append(self.past_attachment.copy())\n",
    "\n",
    "        # Prepare observation for the *next* state\n",
    "        # Use current_tick_index because it reflects the state *after* the step\n",
    "        observation = np.array([self.current_tick_index / self.max_ticks], dtype=np.float32)\n",
    "        info = {} # Store additional info if needed\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def close(self):\n",
    "        # Implement any necessary cleanup\n",
    "        pass\n",
    "\n",
    "# %%\n",
    "# (RewardCallback definition should be here if not already defined)\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class RewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A simple callback that can be used to print information during training.\n",
    "    Modify it to log or print specific details as needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RewardCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if episode is finished (using dones flag from locals, which combines terminated/truncated)\n",
    "        if self.locals[\"dones\"][0]:\n",
    "            info = self.locals[\"infos\"][0]\n",
    "            if 'episode' in info: # Check if Monitor wrapper added episode info\n",
    "                print(f\"Episode finished. Length={info['episode']['l']}, Reward={info['episode']['r']:.2f}\")\n",
    "                self.episode_rewards.append(info['episode']['r'])\n",
    "                self.episode_lengths.append(info['episode']['l'])\n",
    "        return True # Continue training\n",
    "\n",
    "# %%\n",
    "# Instantiate and train (ensure train_data, topology are defined)\n",
    "\n",
    "# Assuming train_data and topology are loaded and preprocessed correctly\n",
    "train_env = MRO_Env(train_data, topology, calculate_mro_metric, train_mode=True)\n",
    "print(\"** train_env created (using gymnasium)\")\n",
    "\n",
    "# PPO should automatically wrap the env with Monitor and DummyVecEnv if it's not a VecEnv\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "print(\"** model created\")\n",
    "\n",
    "reward_callback = RewardCallback()\n",
    "print(\"** reward callback created\")\n",
    "\n",
    "total_timesteps = 10000 # Adjust as needed\n",
    "model.learn(total_timesteps=total_timesteps, callback=reward_callback)\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fd3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65618c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bcd3fbb",
   "metadata": {},
   "source": [
    "## TEST RL:\n",
    "Depending upon whether we used old MRO or New MRO, test_env accommodates the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d478e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lk/Projects/accelcq-repos/cloudly/maveric/venv/lib/python3.9/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/home/lk/Projects/accelcq-repos/cloudly/maveric/venv/lib/python3.9/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL Model - Total MRO Metric on Test Data: -2.4000000000000004\n",
      "RL Model - Hysteresis Values on Test Data: [0.004759658, 0.022449465, 0.04012832, 0.057772517, 0.07535865, 0.09286385, 0.11026597, 0.12754375, 0.144677, 0.16164668, 0.1784351, 0.19502586, 0.211404, 0.22755598, 0.24346964, 0.25913423, 0.2745404, 0.28968003, 0.30454642, 0.31913388]\n",
      "RL Model - Time-to-Trigger Values on Test Data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Testing the RL Model ----------------------\n",
    "\n",
    "# Instantiate the testing environment using the 'test_data'\n",
    "test_env = MRO_Env(test_data, topology, calculate_mro_metric, train_mode=False)\n",
    "\n",
    "# Reset the environment to get the initial observation\n",
    "obs, _ = test_env.reset() # Use Gymnasium reset signature\n",
    "done = False\n",
    "total_reward_rl = 0\n",
    "rl_hyst_values = []\n",
    "rl_ttt_values = []\n",
    "\n",
    "# Loop through the time steps of the test episode\n",
    "while not done:\n",
    "    # *** KEY STEP ***\n",
    "    # Use the trained 'model' to predict the BEST action for the current observation\n",
    "    # 'deterministic=True' means NO exploration noise, just exploit the learned policy\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "    # Take the chosen action in the test environment\n",
    "    # Environment calculates next state, reward (at end), done flags based on this action\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action) # Use Gymnasium step signature\n",
    "    done = terminated or truncated # Check if episode ended\n",
    "\n",
    "    # Accumulate reward (remember reward is likely 0 until the very last step)\n",
    "    total_reward_rl += reward\n",
    "\n",
    "    # Store the actions chosen by the RL agent\n",
    "    rl_hyst_values.append(action[0])\n",
    "    rl_ttt_values.append(int(round(action[1]))) # Assuming ttt is the second action element\n",
    "\n",
    "# Print the results for the RL agent\n",
    "print(f\"RL Model - Total MRO Metric on Test Data: {total_reward_rl}\")\n",
    "# (Optional: print hyst/ttt values)\n",
    "print(f\"RL Model - Hysteresis Values on Test Data: {rl_hyst_values}\")\n",
    "print(f\"RL Model - Time-to-Trigger Values on Test Data: {rl_ttt_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4367adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Hysteresis Analysis ---\n",
      "Average Hyst: 0.1670195758\n",
      "Median Hyst: 0.1700408906\n",
      "Min Hyst: 0.0047596581\n",
      "Max Hyst: 0.3191338778\n",
      "\n",
      "--- Time-to-Trigger Analysis ---\n",
      "Average TTT: 1.00\n",
      "Median TTT: 1.00\n",
      "Mode TTT: 1\n",
      "------------------------------------------------------------\n",
      "Suggested fixed parameters: Hyst=0.1700, TTT=1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming rl_hyst_values and rl_ttt_values are populated after running the RL test block\n",
    "\n",
    "if rl_hyst_values and rl_ttt_values: # Check if lists are not empty\n",
    "    # --- Hysteresis Analysis ---\n",
    "    avg_hyst = np.mean(rl_hyst_values)\n",
    "    median_hyst = np.median(rl_hyst_values)\n",
    "\n",
    "    # Print with high precision\n",
    "    print(f\"--- Hysteresis Analysis ---\")\n",
    "    print(f\"Average Hyst: {avg_hyst:.10f}\") # Increased precision\n",
    "    print(f\"Median Hyst: {median_hyst:.10f}\") # Increased precision\n",
    "    print(f\"Min Hyst: {np.min(rl_hyst_values):.10f}\")\n",
    "    print(f\"Max Hyst: {np.max(rl_hyst_values):.10f}\")\n",
    "\n",
    "    # --- TTT Analysis ---\n",
    "    avg_ttt = np.mean(rl_ttt_values)\n",
    "    median_ttt = np.median(rl_ttt_values)\n",
    "    # Use pandas Series for a robust mode calculation\n",
    "    mode_ttt_result = pd.Series(rl_ttt_values).mode()\n",
    "    optimal_ttt_mode = int(mode_ttt_result[0]) if not mode_ttt_result.empty else 1 # Default to 1 if no mode\n",
    "\n",
    "    print(f\"\\n--- Time-to-Trigger Analysis ---\")\n",
    "    print(f\"Average TTT: {avg_ttt:.2f}\")\n",
    "    print(f\"Median TTT: {median_ttt:.2f}\")\n",
    "    print(f\"Mode TTT: {optimal_ttt_mode}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Suggestion based on calculated values\n",
    "    # Since hyst values are consistently very close to 0, median/average are similar\n",
    "    suggested_hyst = median_hyst\n",
    "    # TTT is consistently 1\n",
    "    suggested_ttt = optimal_ttt_mode\n",
    "\n",
    "    # Format suggested hyst to avoid scientific notation if very small\n",
    "    hyst_format = \".4f\" if suggested_hyst > 1e-4 else \".10f\"\n",
    "\n",
    "    print(f\"Suggested fixed parameters: Hyst={suggested_hyst:{hyst_format}}, TTT={suggested_ttt}\")\n",
    "\n",
    "else:\n",
    "    print(\"RL test results (hyst/ttt values) are empty. Cannot analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982900b",
   "metadata": {},
   "source": [
    "## Baseline Test for new MRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Testing with Constant Values (Baseline) ----------------------\n",
    "\n",
    "constant_hyst = 2.0 # Example fixed value\n",
    "constant_ttt = 3    # Example fixed value\n",
    "\n",
    "# --- Note: This part manually simulates, not using env.step fully ---\n",
    "# It re-implements the simulation loop using fixed parameters\n",
    "\n",
    "# Initialize history specific to this baseline test\n",
    "constant_strongest_server_history = []\n",
    "# Ensure past_attachment is initialized correctly\n",
    "required_cols_for_history = ['ue_id', 'cell_id', 'tick', 'cell_rxpower_dbm'] # Make sure this matches env\n",
    "constant_past_attachment = pd.DataFrame(columns=required_cols_for_history)\n",
    "constant_past_attachment_history = [] # Store results for final calculation\n",
    "\n",
    "test_ticks_baseline = sorted(test_data['tick'].unique()) # Get ticks from test_data\n",
    "\n",
    "# Loop through ticks in the test data\n",
    "for tick_idx, current_tick_constant in enumerate(test_ticks_baseline):\n",
    "    current_tick_data_constant = test_data[test_data['tick'] == current_tick_constant].copy()\n",
    "\n",
    "    # Determine if initial phase based on constant_ttt\n",
    "    use_strongest_server_baseline = len(constant_strongest_server_history) < constant_ttt - 1\n",
    "\n",
    "    # Manually call the core MRO logic function with CONSTANT hyst/ttt\n",
    "    constant_strongest_server_history, current_attachment_baseline = perform_attachment_hyst_ttt_per_tick(\n",
    "        current_tick_data_constant,\n",
    "        constant_strongest_server_history,\n",
    "        constant_past_attachment.copy(), # Pass copy\n",
    "        constant_ttt,                   # Use fixed TTT\n",
    "        constant_hyst,                  # Use fixed Hyst\n",
    "        use_strongest_server=use_strongest_server_baseline\n",
    "    )\n",
    "\n",
    "    # Update past_attachment for the baseline simulation state\n",
    "    if not current_attachment_baseline.empty:\n",
    "         # Ensure tick column exists (it should, but double-check)\n",
    "         if 'tick' not in current_attachment_baseline.columns:\n",
    "              current_attachment_baseline['tick'] = current_tick_constant\n",
    "         if all(col in current_attachment_baseline.columns for col in required_cols_for_history):\n",
    "              constant_past_attachment = current_attachment_baseline[required_cols_for_history].copy()\n",
    "              # Append valid attachment to history list\n",
    "              constant_past_attachment_history.append(constant_past_attachment.copy())\n",
    "         # else: constant_past_attachment remains unchanged if columns missing\n",
    "\n",
    "\n",
    "# --- Calculate final reward for baseline ---\n",
    "# Inside the baseline test block, after the loop:\n",
    "if not constant_past_attachment_history:\n",
    "    print(\"Warning: Baseline history is empty.\")\n",
    "    total_reward_constant = -np.inf # Or appropriate score for failure/no data\n",
    "else:\n",
    "    final_df_constant = pd.concat(constant_past_attachment_history).reset_index(drop=True)\n",
    "    if not final_df_constant.empty:\n",
    "        # *** Use the new counting function ***\n",
    "        ho_count_const, pp_count_const = count_switches_and_pingpongs(final_df_constant, pp_window=5) # Use same window\n",
    "        rlf_count_const = count_rlf(final_df_constant)\n",
    "        total_ticks_in_episode_const = len(test_ticks_baseline) # Or len(test_data['tick'].unique())\n",
    "\n",
    "        # *** Use the same NEW reward function as the RL Env ***\n",
    "        total_reward_constant = calculate_mro_metric_v2(\n",
    "            ho_count_const, pp_count_const, rlf_count_const, total_ticks_in_episode_const,\n",
    "            base_ho_penalty_s=0.1,  # Use consistent penalty values\n",
    "            pp_extra_penalty_s=0.4,\n",
    "            rlf_penalty_s=1.0\n",
    "        )\n",
    "    else:\n",
    "        total_reward_constant = -np.inf # Or appropriate score\n",
    "\n",
    "\n",
    "print(f\"Constant Values - Total MRO Metric on Test Data: {total_reward_constant}\")\n",
    "print(f\"Constant Hysteresis: {constant_hyst}, Constant Time-to-Trigger: {constant_ttt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eca998",
   "metadata": {},
   "source": [
    "## Baseline Test for old MRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Testing with Constant Values (Baseline) ----------------------\n",
    "\n",
    "constant_hyst = 2.0 # Example fixed value\n",
    "constant_ttt = 3    # Example fixed value\n",
    "\n",
    "# --- Note: This part manually simulates, not using env.step fully ---\n",
    "# It re-implements the simulation loop using fixed parameters\n",
    "\n",
    "# Initialize history specific to this baseline test\n",
    "constant_strongest_server_history = []\n",
    "# Ensure past_attachment is initialized correctly\n",
    "required_cols_for_history = ['ue_id', 'cell_id', 'tick', 'cell_rxpower_dbm'] # Make sure this matches env\n",
    "constant_past_attachment = pd.DataFrame(columns=required_cols_for_history)\n",
    "constant_past_attachment_history = [] # Store results for final calculation\n",
    "\n",
    "test_ticks_baseline = sorted(test_data['tick'].unique()) # Get ticks from test_data\n",
    "\n",
    "# Loop through ticks in the test data\n",
    "for tick_idx, current_tick_constant in enumerate(test_ticks_baseline):\n",
    "    current_tick_data_constant = test_data[test_data['tick'] == current_tick_constant].copy()\n",
    "\n",
    "    # Determine if initial phase based on constant_ttt\n",
    "    use_strongest_server_baseline = len(constant_strongest_server_history) < constant_ttt - 1\n",
    "\n",
    "    # Manually call the core MRO logic function with CONSTANT hyst/ttt\n",
    "    constant_strongest_server_history, current_attachment_baseline = perform_attachment_hyst_ttt_per_tick(\n",
    "        current_tick_data_constant,\n",
    "        constant_strongest_server_history,\n",
    "        constant_past_attachment.copy(), # Pass copy\n",
    "        constant_ttt,                   # Use fixed TTT\n",
    "        constant_hyst,                  # Use fixed Hyst\n",
    "        use_strongest_server=use_strongest_server_baseline\n",
    "    )\n",
    "\n",
    "    # Update past_attachment for the baseline simulation state\n",
    "    if not current_attachment_baseline.empty:\n",
    "         # Ensure tick column exists (it should, but double-check)\n",
    "         if 'tick' not in current_attachment_baseline.columns:\n",
    "              current_attachment_baseline['tick'] = current_tick_constant\n",
    "         if all(col in current_attachment_baseline.columns for col in required_cols_for_history):\n",
    "              constant_past_attachment = current_attachment_baseline[required_cols_for_history].copy()\n",
    "              # Append valid attachment to history list\n",
    "              constant_past_attachment_history.append(constant_past_attachment.copy())\n",
    "         # else: constant_past_attachment remains unchanged if columns missing\n",
    "\n",
    "\n",
    "# --- Calculate final reward for baseline ---\n",
    "total_reward_constant = 0\n",
    "if not constant_past_attachment_history:\n",
    "    print(\"Warning: Baseline history is empty.\")\n",
    "else:\n",
    "    final_df_constant = pd.concat(constant_past_attachment_history).reset_index(drop=True)\n",
    "    if not final_df_constant.empty:\n",
    "        handovers_constant = count_switches(final_df_constant)\n",
    "        rlf_count_constant = count_rlf(final_df_constant)\n",
    "        # Use the original reward function\n",
    "        total_reward_constant = calculate_mro_metric(handovers_constant, rlf_count_constant, test_data)\n",
    "\n",
    "\n",
    "print(f\"Constant Values - Total MRO Metric on Test Data: {total_reward_constant}\")\n",
    "print(f\"Constant Hysteresis: {constant_hyst}, Constant Time-to-Trigger: {constant_ttt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad0857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7a49ef7",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cb9ab97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./mro_ppo_model2.zip\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' trained PPO model\n",
    "model_save_path = \"./mro_ppo_model2.zip\" # Choose a path and filename\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ee36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569c4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d4c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e8ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
